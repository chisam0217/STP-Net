{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26b9dd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d878fc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"/home/xiao/Projects/predrnn-pytorch/data/moving-mnist-example/moving-mnist-test.npz\"\n",
    "# data = {}\n",
    "# dat_1 = np.load(path)\n",
    "# for key in dat_1.keys():\n",
    "#     print ('key', key)\n",
    "#     data[key] = dat_1[key]\n",
    "# print ('data[clips]', data['clips'], data['clips'].shape)\n",
    "# print ('data[dims]', data['dims'])\n",
    "# print ('data[input_raw_data]', data['input_raw_data'], data['input_raw_data'].shape, np.median(data['input_raw_data']), np.max(data['input_raw_data']))\n",
    "\n",
    "# path = \"/home/xiao/Projects/ST_LSTM_MP/Data/2D_map/Map_array/normalized_train_video.npz\"\n",
    "# data = np.load(path)\n",
    "# for key in data.keys():\n",
    "#     print ('key', key)\n",
    "\n",
    "# print ('data[clips]', data['clips'].shape)\n",
    "# print ('data[dims]', data['dims'])\n",
    "# print ('data[input_raw_data]', data['input_raw_data'].shape, np.median(data['input_raw_data']), np.max(data['input_raw_data']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21a72501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111\n"
     ]
    }
   ],
   "source": [
    "import os.path as op\n",
    "arr_dir = \"../../Data/2D_map/Map_array\"\n",
    "total_maz = np.load(op.join(arr_dir, 'maz.npy'))\n",
    "print (\"111\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e3893bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_maz (120, 128, 128)\n",
      "train_path (160000, 22, 2)\n"
     ]
    }
   ],
   "source": [
    "train_file = op.join(arr_dir, \"train_path.npy\")\n",
    "train_path = np.load(train_file)\n",
    "\n",
    "print ('total_maz', total_maz.shape)\n",
    "print ('train_path', train_path.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e478868b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_path (100, 1600, 22, 2) 127 0\n"
     ]
    }
   ],
   "source": [
    "train_path = np.reshape(train_path, (100, -1, train_path.shape[1], train_path.shape[2]))\n",
    "print ('train_path', train_path.shape, np.max(train_path), np.min(train_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97033088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_video (100, 1000, 22, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "train_video = []\n",
    "for maz_id in range(train_path.shape[0]):\n",
    "    video_per_maz = []\n",
    "#     for task_id in range(train_path.shape[1]):\n",
    "    for task_id in range(1000):\n",
    "        start, goal = train_path[maz_id][task_id][0], train_path[maz_id][task_id][1]\n",
    "        maz = np.copy(total_maz[maz_id])\n",
    "        maz[start] = 64\n",
    "        maz[goal] = 192\n",
    "        repeated_maz = np.tile(maz, (train_path.shape[2], 1))\n",
    "        repeated_maz = np.reshape(repeated_maz, (train_path.shape[2], maz.shape[0], maz.shape[1]))\n",
    "#         print (repeated_maz.shape)\n",
    "        for path_id in range(1, train_path.shape[2]-1):\n",
    "            pos = train_path[maz_id][task_id][path_id]\n",
    "#             print ('pos', pos)\n",
    "#             print ('repeated_maz[path_id:-1]', repeated_maz[path_id:-1].shape)\n",
    "            repeated_maz[path_id:, pos] = 128\n",
    "#             for i in range(path_id, )\n",
    "        video_per_maz.append(repeated_maz)\n",
    "    video_per_maz = np.array(video_per_maz)\n",
    "#     print ('video_per_maz', video_per_maz.shape)\n",
    "    train_video.append(video_per_maz)\n",
    "train_video = np.stack(train_video)\n",
    "print ('train_video', train_video.shape)\n",
    "video_num = train_video.shape[0] * 1000\n",
    "video_len = train_video.shape[2]\n",
    "\n",
    "np.save(op.join(arr_dir, \"train_video.npy\"), train_video)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c97a8506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_video (2200000, 1, 128, 128)\n",
      "(2, 100000, 2)\n"
     ]
    }
   ],
   "source": [
    "train_video = np.reshape(train_video, (-1, 1, train_video.shape[3], train_video.shape[4])).astype(np.float32)\n",
    "print ('train_video', train_video.shape)\n",
    "train_video = train_video/255.0\n",
    "dims = np.array([1, train_video.shape[-2], train_video.shape[-1]])\n",
    "dims = np.expand_dims(dims, axis=0)\n",
    "# print (dims)\n",
    "input_seq = 10\n",
    "input_start = np.arange(0, video_num*video_len, video_len).astype(np.int32)\n",
    "output_start = np.arange(input_seq, video_num*video_len, video_len).astype(np.int32)\n",
    "# print (input_start.shape,input_start)\n",
    "# print (output_start.shape, output_start)\n",
    "# print (np.ones(video_num).astype(np.int32).shape)\n",
    "input_start = np.stack((input_start, input_seq * np.ones(video_num).astype(np.int32)))\n",
    "output_start = np.stack((output_start, (video_len-input_seq) * np.ones(video_num).astype(np.int32)))\n",
    "input_start = np.transpose(input_start)\n",
    "output_start = np.transpose(output_start)\n",
    "# print (input_start.shape,input_start)\n",
    "# print (output_start.shape, output_start)\n",
    "clips = np.stack((input_start, output_start))\n",
    "print (clips.shape)\n",
    "np.savez(op.join(arr_dir, \"normalized_train_video.npz\"), dims=dims, clips=clips, input_raw_data=train_video)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2cd99b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_seen_path (40000, 19, 2)\n",
      "test_seen_path (100, 400, 19, 2)\n"
     ]
    }
   ],
   "source": [
    "test_seen_file = op.join(arr_dir, \"test_seen_path.npy\")\n",
    "test_seen_path = np.load(test_seen_file)\n",
    "print ('test_seen_path', test_seen_path.shape)\n",
    "\n",
    "test_seen_path = np.reshape(test_seen_path, (100, -1, test_seen_path.shape[1], test_seen_path.shape[2]))\n",
    "print ('test_seen_path', test_seen_path.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b35bf8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_seen_video (100, 200, 19, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "test_seen_video = []\n",
    "for maz_id in range(test_seen_path.shape[0]):\n",
    "    video_per_maz = []\n",
    "#     for task_id in range(test_seen_path.shape[1]):\n",
    "    for task_id in range(200):\n",
    "        start, goal = test_seen_path[maz_id][task_id][0], test_seen_path[maz_id][task_id][1]\n",
    "        maz = np.copy(total_maz[maz_id])\n",
    "        maz[start[0], start[1]] = 64 #XXXXX\n",
    "        maz[goal[0], goal[1]] = 192 #XXXXX\n",
    "        repeated_maz = np.tile(maz, (test_seen_path.shape[2], 1))\n",
    "#         print ('tile', repeated_maz.shape)\n",
    "        repeated_maz = np.reshape(repeated_maz, (test_seen_path.shape[2], maz.shape[0], maz.shape[1]))\n",
    "#         print ('reshape', repeated_maz.shape)\n",
    "#         \n",
    "        for path_id in range(1, test_seen_path.shape[2]-1):\n",
    "            pos = test_seen_path[maz_id][task_id][path_id]\n",
    "#             print ('pos', pos)\n",
    "#             print ('repeated_maz[path_id:-1]', repeated_maz[path_id:-1].shape)\n",
    "            repeated_maz[path_id:-1, pos[0], pos[1]] = 128 #XXXXX\n",
    "        video_per_maz.append(repeated_maz)\n",
    "    video_per_maz = np.array(video_per_maz)\n",
    "    test_seen_video.append(video_per_maz)\n",
    "test_seen_video = np.array(test_seen_video)\n",
    "print ('test_seen_video', test_seen_video.shape)\n",
    "# video_num = test_seen_video.shape[0] * test_seen_video.shape[1]\n",
    "video_num = test_seen_video.shape[0] * 200\n",
    "video_len = test_seen_video.shape[2]\n",
    "np.save(op.join(arr_dir, \"test_seen_video.npy\"), test_seen_video)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d877ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 20000, 2)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_262963/362086313.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mclips\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mclips\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavez\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"normalized_test_seen_video.npz\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclips\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclips\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_raw_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_seen_video\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msavez\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch19/lib/python3.8/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36msavez\u001b[0;34m(file, *args, **kwds)\u001b[0m\n\u001b[1;32m    615\u001b[0m     \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m     \"\"\"\n\u001b[0;32m--> 617\u001b[0;31m     \u001b[0m_savez\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch19/lib/python3.8/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36m_savez\u001b[0;34m(file, args, kwds, compress, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[0;31m# always force zip64, gh-10776\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mzipf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_zip64\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m             format.write_array(fid, val,\n\u001b[0m\u001b[1;32m    721\u001b[0m                                \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_pickle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m                                pickle_kwargs=pickle_kwargs)\n",
      "\u001b[0;32m~/anaconda3/envs/torch19/lib/python3.8/site-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mwrite_array\u001b[0;34m(fp, array, version, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    690\u001b[0m                     \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'external_loop'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'buffered'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'zerosize_ok'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                     buffersize=buffersize, order='C'):\n\u001b[0;32m--> 692\u001b[0;31m                 \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch19/lib/python3.8/zipfile.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1139\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compress_size\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fileobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_seen_video = np.reshape(test_seen_video, (-1, 1, test_seen_video.shape[3], test_seen_video.shape[4])).astype(np.float32)\n",
    "test_seen_video = test_seen_video/255.0\n",
    "dims = np.array([1, test_seen_video.shape[-2], test_seen_video.shape[-1]])\n",
    "dims = np.expand_dims(dims, axis=0)\n",
    "# print (dims)\n",
    "input_seq = 1\n",
    "input_start = np.arange(0, video_num*video_len, video_len).astype(np.int32)\n",
    "output_start = np.arange(input_seq, video_num*video_len, video_len).astype(np.int32)\n",
    "# print (input_start.shape,input_start)\n",
    "# print (output_start.shape, output_start)\n",
    "# print (np.ones(video_num).astype(np.int32).shape)\n",
    "input_start = np.stack((input_start, input_seq * np.ones(video_num).astype(np.int32)))\n",
    "output_start = np.stack((output_start, (video_len-input_seq) * np.ones(video_num).astype(np.int32)))\n",
    "input_start = np.transpose(input_start)\n",
    "output_start = np.transpose(output_start)\n",
    "# print (input_start.shape,input_start)\n",
    "# print (output_start.shape, output_start)\n",
    "clips = np.stack((input_start, output_start))\n",
    "print (clips.shape)\n",
    "np.savez(op.join(arr_dir, \"normalized_test_seen_video.npz\"), dims=dims, clips=clips, input_raw_data=test_seen_video)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "670f1fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_unseen_path (8000, 17, 2)\n",
      "test_unseen_path (20, 400, 17, 2)\n"
     ]
    }
   ],
   "source": [
    "test_unseen_file = op.join(arr_dir, \"test_unseen_path.npy\")\n",
    "test_unseen_path = np.load(test_unseen_file)\n",
    "print ('test_unseen_path', test_unseen_path.shape)\n",
    "\n",
    "test_unseen_path = np.reshape(test_unseen_path, (20, -1, test_unseen_path.shape[1], test_unseen_path.shape[2]))\n",
    "print ('test_unseen_path', test_unseen_path.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b772df96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_video (20, 400, 17, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "test_unseen_video = []\n",
    "for maz_id in range(test_unseen_path.shape[0]):\n",
    "    video_per_maz = []\n",
    "    for task_id in range(test_unseen_path.shape[1]):\n",
    "        start, goal = test_unseen_path[maz_id][task_id][0], test_unseen_path[maz_id][task_id][1]\n",
    "        maz = np.copy(total_maz[100 + maz_id])\n",
    "        maz[start[0],start[1]] = 64\n",
    "        maz[goal[0],goal[1]] = 192 #XXXXXX\n",
    "        repeated_maz = np.tile(maz, (test_unseen_path.shape[2], 1))\n",
    "        repeated_maz = np.reshape(repeated_maz, (test_unseen_path.shape[2], maz.shape[0], maz.shape[1]))\n",
    "#         print (repeated_maz.shape)\n",
    "        for path_id in range(1, test_unseen_path.shape[2]-1):\n",
    "            pos = test_unseen_path[maz_id][task_id][path_id]\n",
    "#             print ('pos', pos)\n",
    "#             print ('repeated_maz[path_id:-1]', repeated_maz[path_id:-1].shape)\n",
    "            repeated_maz[path_id:-1, pos] = 128\n",
    "#             for i in range(path_id, )\n",
    "        video_per_maz.append(repeated_maz)\n",
    "    video_per_maz = np.array(video_per_maz)\n",
    "    test_unseen_video.append(video_per_maz)\n",
    "test_unseen_video = np.array(test_unseen_video)\n",
    "print ('test_unseen_video', test_unseen_video.shape)\n",
    "video_num = test_unseen_video.shape[0] * test_unseen_video.shape[1]\n",
    "video_len = test_unseen_video.shape[2]\n",
    "np.save(op.join(arr_dir, \"test_unseen_video.npy\"), test_unseen_video)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc1510aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 8000, 2)\n"
     ]
    }
   ],
   "source": [
    "test_unseen_video = np.reshape(test_unseen_video, (-1, 1, test_unseen_video.shape[3], test_unseen_video.shape[4])).astype(np.float32)\n",
    "test_unseen_video = test_seen_video/255.0\n",
    "dims = np.array([1, test_unseen_video.shape[-2], test_unseen_video.shape[-1]])\n",
    "dims = np.expand_dims(dims, axis=0)\n",
    "# print (dims)\n",
    "input_seq = 1\n",
    "input_start = np.arange(0, video_num*video_len, video_len).astype(np.int32)\n",
    "output_start = np.arange(input_seq, video_num*video_len, video_len).astype(np.int32)\n",
    "# print (input_start.shape,input_start)\n",
    "# print (output_start.shape, output_start)\n",
    "# print (np.ones(video_num).astype(np.int32).shape)\n",
    "input_start = np.stack((input_start, input_seq * np.ones(video_num).astype(np.int32)))\n",
    "output_start = np.stack((output_start, (video_len-input_seq) * np.ones(video_num).astype(np.int32)))\n",
    "input_start = np.transpose(input_start)\n",
    "output_start = np.transpose(output_start)\n",
    "# print (input_start.shape,input_start)\n",
    "# print (output_start.shape, output_start)\n",
    "clips = np.stack((input_start, output_start))\n",
    "print (clips.shape)\n",
    "np.savez(op.join(arr_dir, \"normalized_test_unseen_video.npz\"), dims=dims, clips=clips, input_raw_data=test_unseen_video)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f476665",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d95c7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
